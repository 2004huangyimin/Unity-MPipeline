// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel ClusterFunc
#pragma kernel PointFunc
#pragma kernel MaterialFunc
#pragma kernel IndexFunc
#pragma kernel MipGroupSync
#pragma kernel BlitTo
#pragma kernel BlitTo BLIT_NORMAL
#pragma kernel ClearTargetSceneBuffer
#pragma kernel CollectTargetScene
#pragma kernel ExecuteClusterMoving
#pragma kernel ExecutePointMoving
#pragma kernel ExecuteClusterMoving MOVE_ALL
#pragma kernel ExecutePointMoving MOVE_ALL
#define COMPUTESHADER
#include "CGINC/Procedural.cginc"
#include "UnityCG.cginc"
struct ClusterMeshData
{
    float3 extent;
    float3 position;
    int index;
};
RWStructuredBuffer<ClusterMeshData> clusterBuffer;
RWStructuredBuffer<Point> verticesBuffer;
RWStructuredBuffer<int2> _IndexBuffer;
RWStructuredBuffer<int> instanceCountBuffer;//0, 1, 2: x, y, z    3: offset 4:targetScene
uint _Count;
[numthreads(64, 1, 1)]
void ClusterFunc(uint id : SV_DISPATCHTHREADID)
{
    if(id >= _Count) return;
    ClusterMeshData meshData = clusterBuffer[id];
    if(meshData.index == instanceCountBuffer[4])
    {
        int currentIndex;
        do{
            InterlockedAdd(instanceCountBuffer[3], 1, currentIndex);
        }while(clusterBuffer[currentIndex].index == instanceCountBuffer[4]);
        int2 indexLead = int2(id, currentIndex);
        clusterBuffer[indexLead.x] = clusterBuffer[indexLead.y];
        InterlockedAdd(instanceCountBuffer[0], 1, currentIndex);
        _IndexBuffer[currentIndex] = indexLead;
    }
}

[numthreads(1, CLUSTERCLIPCOUNT, 1)]
void PointFunc(uint2 id : SV_DISPATCHTHREADID)
{
    uint2 index = _IndexBuffer[id.x] * CLUSTERCLIPCOUNT + id.y;
    verticesBuffer[index.x] = verticesBuffer[index.y];
}
RWStructuredBuffer<MaterialProperties> _MaterialBuffer;
StructuredBuffer<MaterialProperties> _MaterialAddBuffer;
RWStructuredBuffer<uint> _TriangleMaterialBuffer;
StructuredBuffer<int> _OffsetIndex;
[numthreads(64, 1, 1)]
void MaterialFunc(uint id : SV_DISPATCHTHREADID)
{
    if(id >= _Count) return;
    _MaterialBuffer[_OffsetIndex[id]] = _MaterialAddBuffer[id];
}

[numthreads(1, CLUSTERTRIANGLECOUNT, 1)]
void IndexFunc(uint2 id : SV_DISPATCHTHREADID)
{
    uint2 index = _IndexBuffer[id.x] * CLUSTERTRIANGLECOUNT + id.y;
    _TriangleMaterialBuffer[index.x] = _TriangleMaterialBuffer[index.y];
}

inline uint2 GetDispatchID(uint2 groupID, uint2 threadID, uint2 threadCount)
{
    return groupID * threadCount + threadID;
}

#define CALCULATE_MIP(LastMip, NextMip, groupLength) \
if(threadID.x < groupLength.x && threadID.y < groupLength.y){ \
id = GetDispatchID(groupID, threadID, groupLength);\
idx = id * 2;\
NextMip[uint3(id, _Count)] = 0.25 * (LastMip[uint3(idx, _Count)] + LastMip[uint3(idx + uint2(0, 1), _Count)] + LastMip[uint3(idx + uint2(1, 1), _Count)] + LastMip[uint3(idx + uint2(1, 0), _Count)]); \
} 

#define GROUP_SYNC(groupLength) \
groupLength /= 2;\
AllMemoryBarrierWithGroupSync();\

RWTexture2DArray<float4> _Mip0;
RWTexture2DArray<float4> _Mip1;
RWTexture2DArray<float4> _Mip2;
RWTexture2DArray<float4> _Mip3;
RWTexture2DArray<float4> _Mip4;
RWTexture2DArray<float4> _Mip5;

[numthreads(8, 8, 1)]
void MipGroupSync(/*uint2 groupID : SV_GROUPID, uint2 threadID : SV_GROUPTHREADID*/uint2 id : SV_DISPATCHTHREADID)
{
    uint2 idx = id * 2;
    _Mip1[uint3(id, _Count)] = 0.25 * (_Mip0[uint3(idx, _Count)] + _Mip0[uint3(idx + uint2(0, 1), _Count)] + _Mip0[uint3(idx + uint2(1, 1), _Count)] + _Mip0[uint3(idx + uint2(1, 0), _Count)]); 
    /*
    uint2 idx;
    uint2 id;
    uint2 current_Group_Length = uint2(16,16);
    CALCULATE_MIP(_Mip0, _Mip1, current_Group_Length)
    GROUP_SYNC(current_Group_Length)
    //len = 8
    CALCULATE_MIP(_Mip1, _Mip2, current_Group_Length)
    GROUP_SYNC(current_Group_Length)
    //len = 4
    CALCULATE_MIP(_Mip2, _Mip3, current_Group_Length)
    GROUP_SYNC(current_Group_Length)
    //len = 2
    CALCULATE_MIP(_Mip3, _Mip4, current_Group_Length)
    GROUP_SYNC(current_Group_Length)
    //len = 1
    CALCULATE_MIP(_Mip4, _Mip5, current_Group_Length)*/
}
Texture2D<float4> _SourceTex;
RWTexture2DArray<float4> _DestTex;
inline float4 EncodeFloatRGCustom(float2 v)
{
    float2 kEncodeMul = float2(1, 255);
    float kEncodeBit = 1/255.0;
    float4 enc = kEncodeMul.xyxy * v.xxyy;
    enc = frac(enc);
    enc.xz -= enc.yw * kEncodeBit;
    return enc;
}

[numthreads(8,8,1)]
void BlitTo(uint2 id : SV_DISPATCHTHREADID)
{
    #ifdef BLIT_NORMAL
    _DestTex[uint3(id, _Count)] = EncodeFloatRGCustom(clamp(UnpackNormal(_SourceTex[id]).xy * 0.5 + 0.5, 0, 0.9999));
    #else
    _DestTex[uint3(id, _Count)] = _SourceTex[id];
    #endif
}
RWStructuredBuffer<uint> _TempPropBuffer;
int _TargetElement;

[numthreads(1, 1, 1)]
void ClearTargetSceneBuffer(uint id : SV_DISPATCHTHREADID)
{
    _TempPropBuffer[0] = 0;
}

[numthreads(64,1,1)]
void CollectTargetScene(uint id : SV_DISPATCHTHREADID)
{
    if(id >= _Count) return;
    if(clusterBuffer[id].index == _TargetElement)
    {
        uint currentIndex;
        InterlockedAdd(_TempPropBuffer[0], 1, currentIndex);
        _TempPropBuffer[currentIndex + 1] = id;
    }
}
float3 _OffsetDirection;
uint _Offset;
[numthreads(64, 1, 1)]
void ExecuteClusterMoving(uint id : SV_DISPATCHTHREADID)
{
    if(id >= _Count) return;
    #ifdef MOVE_ALL
    clusterBuffer[id + _Offset].position += _OffsetDirection;
    #else
    clusterBuffer[_TempPropBuffer[id + 1]].position += _OffsetDirection;
    #endif
}

[numthreads(1, CLUSTERCLIPCOUNT, 1)]
void ExecutePointMoving(uint2 id : SV_DISPATCHTHREADID)
{
    #ifdef MOVE_ALL
    verticesBuffer[id.y + (id.x + _Offset) * CLUSTERCLIPCOUNT].vertex += _OffsetDirection;
    #else
    verticesBuffer[id.y + _TempPropBuffer[id.x + 1] * CLUSTERCLIPCOUNT].vertex += _OffsetDirection;
    #endif
}